# v5.8 (Kubernetes)

## What's new

The major changes for the 5.8 Kubernetes upgrade are the following:

- The parameters for CPU and Memory requests and limits are now fully parameterized in the DevOps automation script, providing more flexibility and customization options.
- We migrated the DevOps automation script to run on .NET 6, ensuring compatibility with the latest technologies and features.
- We introduced an exposed parameter for `SSO Enabled` in the DevOps automation script. Manual code changes are no longer necessary, streamlining the SSO configuration process.
- We added `SqlServerReadReplica` into the `ConnectionStrings` section of the IDP and Web app settings in the template. This information is now exposed via the deployment.json, enabling seamless integration with SQL Server Read Replicas.
- We enabled the ability to add custom tags using map string through the DevOps automation script. Users can now define and manage their specific tags effortlessly.
- We exposed a parameter in the DevOps automation script to manage the EKS API endpoint's accessibility. Users can configure it as either private or public, ensuring security and access control based on their requirements.
- We exposed a parameter for EKS IAM roles' additional policies, including permissions such as SSM and ECR image retrieval. This enhancement provides granular control over EKS node policies, enhancing security and compliance measures.
- We added features to customize your application's load balancing behavior. Choose from `STICKY_SESSIONS`, `ROUND_ROBIN`, `RANDOM`, or `LEAST_REQUEST` algorithms to optimize your server resources. Each algorithm provides a unique approach to distributing traffic, allowing you to balance loads effectively.
- We automated the addition of an additional user in OpenSearch through the DevOps automation tool. This process require a reset of the existing OpenSearch setup. For new OpenSearch setups, the user is added automatically.


## Upgrading on Kubernetes

To upgrade your various components, follow the instructions below in the order presented.

## Prerequisites

{% hint style="info" %}
If you have made custom changes to your deployment file structure, please contact your Support team before you upgrade your environments.
{% endhint %}

### Upgrade from 5.1 or lower

If you are upgrading from Cinchy v5.1 or lower to Cinchy v5.8, you must run **Upgrade 5.2** [using the Cinchy Utility](../cinchy-upgrade-utility.md) and deploy version 5.2.

### Upgrade from v5.2 or higher

If you are upgrading from 5.2 or higher, follow the 5.8 upgrade instructions below, then use [the Cinchy Utility](../cinchy-upgrade-utility.md) and deploy the target version using the `-v "X.X"` argument.

### Upgrade from v5.6 or lower
If you are upgrading from v5.6 or lower, follow the 5.7 upgrade steps.

## Configure to the newest version

### Clean existing repositories

1. Go to your **cinchy.argocd** repository. Delete all existing folder structure except for the **.git** folder/directory and any custom changes you may have implemented.
2. Go to your **cinchy.kubernetes** repository. Delete all existing folder structure except for the `.git` file.

{% hint style="danger" %}
If you have `cinchy.kubernetes\cluster_components\servicemesh\istio\istio-injection\argocd-ns.yaml` file and it's not commented, don't change it. Changing this will delete your ArgoCD namespace, which will force you to delete everything from Kubernetes and redeploy.
{% endhint %}

1. Go to your **cinchy.terraform** repository. Delete all existing folder structure except for the `.git` file.
2. Go to your **cinchy.devops.automation** repository. Delete all existing folder structure except for the `.git` file and your **deployment.json**.

### Download k8s template

1. Download and open the new Cinchy `v5.8 k8s-template.zip` file from the **Cinchy Releases** table and place the files into their respective **cinchy.kubernetes**, **cinchy.argocd**, **cinchy.terraform** and **cinchy.devops.automation** repositories.
2. Go to the new `aws.json/azure.json` files and compare them with your current `deployment.json` file. All additional fields in the new `aws.json/azure.json` files should be added to your current `deployment.json`.
3. Update the Kubernetes version in your `deployment.json`. To upgrade EKS to a new version, you need to follow an upgrade sequence, installing each incremental version one by one. For example, you might need to upgrade from 1.24 to 1.25, then from 1.25 to 1.26, and finally from 1.26 to 1.27.

{% hint style="success" %}
You may have changed the name of the `deployment.json` file during your original platform deployment. If so, make sure that you swap up the name wherever it appears in this document.
{% endhint %}

### Upgrade and redeploy components

1.  Open a shell/terminal from the cinchy.devops.automations directory and execute the following command:

    ```bash
    dotnet Cinchy.DevOps.Automations.dll "deployment.json"
    ```
2. Commit all of your changes (if there were any) in each repository.
3. If there were any changes in your **cinchy.argocd** repository you may need to redeploy ArgoCD.Launch a shell/terminal with the working directory set to the root of the **cinchy.argocd** repository.
4.  Execute the following command to deploy ArgoCD:

    ```bash
    bash deploy_argocd.sh
    ```
5. Validate ArgoCD pods are running and check that ArgoCD is upgraded v2.7.6 by accessing the ArgoCD application Console.
6.  Execute the following command to deploy cluster components and Cinchy components:

    ```bash
    bash deploy_cluster_components.sh
    bash deploy_cinchy_components.sh
    ```
7. You might see a couple of ArgoCD apps out of sync. Sync them manually.

### Upgrade AWS EKS and Azure AKS

To upgrade the AWS EKS and Azure AKS version from 1.24 up to 1.27.x, you have two methods. The method depends on the status of the subnet CIDR range. The CIDR is a blocker for Azure only. For AWS export credentials and for Azure run the `az login` command, if required.

1. Go to your **cinchy.devops.automations** repository and change AKS/EKS version in `deployment.json` (or `<cluster name>.json`) within the same directory.
2.  From a shell/terminal, navigate to the **cinchy.devops.automations** directory location and execute the following command:

    ```
    dotnet Cinchy.DevOps.Automations.dll "deployment.json"
    ```

#### AWS - Cinchy.terraform repository structure

The AWS deployment updates a folder named `eks_cluster` in the **Terraform > AWS** directory. Within that directory is a subdirectory with the same name as the created cluster.

To perform terraform operations, the cluster directory must be the working directory during execution.

#### Azure - Cinchy.terraform repository structure

The Azure deployment updates a folder named `aks_cluster` Within the Terraform > Azure directory. Within that directory is a subdirectory with the same name as the created cluster.

For AWS and Azure export credentials run the `az login` command if required.

Run the command below to start the upgrade process. Make sure to verify before you select **yes** to upgrade the process. This shouldn't delete or destroy any data. It runs an in-place deployment that will update the Kubernetes version.

```bash
bash create.sh
```
{% hint style="warning" %}
Before accepting the change, verify that it meets your expectations and ensures the protection of your database and any other resources. This command will create, update, or destroy vnet, subnet, AKS cluster, and AKS node groups. Make sure to review the changes before proceeding.
{% endhint %}
